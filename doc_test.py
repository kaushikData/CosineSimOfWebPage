from DatumBox import DatumBox
datum_box = DatumBox("2a13913dda346761765020c1f66e34f8")
#import networkx as nx
#import matplotlib.pyplot as plt
import urllib2
import re
import nltk, string
from sklearn.feature_extraction.text import TfidfVectorizer
from nltk.stem.snowball import SnowballStemmer
from nltk.corpus import stopwords
TAG_RE = re.compile(r"<[^>]+>")


nltk.download('punkt') 
stemmer = nltk.stem.porter.PorterStemmer()
remove_punctuation_map = dict((ord(char), None) for char in string.punctuation)


def fetch_page(siteURL):
    # create a variable which will hold our desired web page as a string
    site= siteURL
    # create the approprriate headers for our http request so that we wont run
    # into any 403 forbidden errors. All of this will be available at the tutorial
    # page that I will link to in the description below
    hdr = {'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.11 (KHTML, like Gecko) Chrome/23.0.1271.64 Safari/537.11',
           'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
           'Accept-Charset': 'ISO-8859-1,utf-8;q=0.7,*;q=0.3',
           'Accept-Encoding': 'none',
           'Accept-Language': 'en-US,en;q=0.8',
           'Connection': 'keep-alive'}

    # Perform a HTTP request by passing in our desired URL and setting our headers to equal
    # the headers that we've defined above.
    req = urllib2.Request(site, headers=hdr)

    # 
    try:
        # here we are going to open our desired page using urllib2.urlopen
        # and passing in our request object as a parameter and as a means of protection we 
        # will surround this with a try except so that, should the script run into any errors
        # it will fail gracefully instead of just crashing.
        page = urllib2.urlopen(req)
    except urllib2.HTTPError, e:
        # print out the HTTPError
        print e.fp.read()

    # lastly we will want to read the response which was generated by opening
    # the url and store it under content
    content = page.read()
    # and then print out this page.
    return content

def remove_tags(text):
    return TAG_RE.sub('', text)



def stem_tokens(tokens):
    return [stemmer.stem(item) for item in tokens]

'''remove punctuation, lowercase, stem'''
def normalize(text):
    return stem_tokens(nltk.word_tokenize(text.lower().translate(remove_punctuation_map)))

vectorizer = TfidfVectorizer(tokenizer=normalize, stop_words='english') 

def cosine_sim(text1, text2):
    tfidf = vectorizer.fit_transform([text1, text2])
    return ((tfidf * tfidf.T).A)[0,1]



stemmer = nltk.stem.porter.PorterStemmer()
remove_punctuation_map = dict((ord(char), None) for char in string.punctuation)
print "crawling first page"    
page1 = fetch_page("http://www.geeksforgeeks.org/fundamentals-of-algorithms/")
page2 = fetch_page("http://www.geeksforgeeks.org/data-structures/")
print "extracting data from page1"
str1 = datum_box.text_extract(page1)
print "extracting data from page2"
str2 = datum_box.text_extract(page2)
print cosine_sim(str1,str2)
#print cosine_sim('The internet is going to be biased','humans evolved swiftly in this century')
#print cosine_sim('masters in us', 'masters')
   
print "hello world"
